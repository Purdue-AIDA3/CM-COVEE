{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/cyan/AIDA3/cogmd/video_models/cv_models_code/ViViT\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pad_image(image, target_size):\n",
    "    \"\"\"\n",
    "    Pads an image to a specified size.\n",
    "\n",
    "    Args:\n",
    "        image: The image to be padded (numpy array).\n",
    "        target_size: The desired size of the padded image (tuple of integers (height, width)).\n",
    "\n",
    "    Returns:\n",
    "        The padded image (numpy array).\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the original image shape\n",
    "    h, w = image.shape[:2]\n",
    "    old_image_height, old_image_width, channels = image.shape\n",
    "\n",
    "    # Calculate the amount of padding needed for each dimension\n",
    "    new_image_width = target_size[0]\n",
    "    new_image_height = target_size[1]\n",
    "    color = (0,0,0)\n",
    "    result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
    "\n",
    "    # compute center offset\n",
    "    x_center = (new_image_width - old_image_width) // 2\n",
    "    y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "    # copy img image into center of result image\n",
    "    result[y_center:y_center+old_image_height,\n",
    "        x_center:x_center+old_image_width] = image\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_given_size(a, size, axis):\n",
    "    return np.split(a, np.arange(size,len(a),size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COGNITIVE LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../label_generation/cognitive_load_labels.csv\")\n",
    "# template = np.zeros((2, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(num_frames, folder, pad):\n",
    "    for user in os.listdir(\"../../user_data/\"):\n",
    "        for task_name in os.listdir(\"../../user_data/\" + user + \"/Video/Task 1/Facial Features/\"):\n",
    "            if task_name == \".DS_Store\":\n",
    "                continue\n",
    "            to_save = task_name if task_name[-1] != \"y\" else task_name[:-10]\n",
    "            c1 = df[\"User ID\"] == int(user)\n",
    "            c2 = df[\"Task ID\"] == task_name\n",
    "            filtered_df = df[c1 & c2]\n",
    "            if len(filtered_df) == 0:\n",
    "                print(f\"User {user} on task {task_name} is not available in the csv file\")\n",
    "            else:\n",
    "                print(f\"Creating data file for user {user}, task {task_name}\")\n",
    "                label = filtered_df['Labels'].iloc[0]\n",
    "                task_data = []\n",
    "                video_path = \"../../simple_datasets/Task 1/\" + folder + \"/\" + user + \"_\" + to_save\n",
    "                for frame in sorted(os.listdir(\"../../user_data/\" + user + \"/Video/Task 1/Facial Features/\" + task_name + \"/\" + task_name + \"_aligned/\")):\n",
    "                    image_path = \"../../user_data/\" + user + \"/Video/Task 1/Facial Features/\" + task_name + \"/\" + task_name + \"_aligned/\" + frame\n",
    "                    image = cv2.imread(image_path)\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    print(image_path)\n",
    "                    if pad:\n",
    "                        image = custom_pad_image(image, target_size=(224, 224))\n",
    "                    numpy_data = np.asarray(image).astype(np.float32)\n",
    "                    numpy_data = numpy_data.transpose(2, 1, 0)\n",
    "                    numpy_data = numpy_data / 255\n",
    "                    task_data.append(numpy_data)\n",
    "                task_data = np.array(task_data)\n",
    "                # print(task_data.shape)\n",
    "                chunks = split_given_size(a=task_data, size=32, axis=0)\n",
    "                for counter, chunk in enumerate(chunks):\n",
    "                    # chunk = np.concatenate((chunk, template), axis=0)\n",
    "                    if chunk.shape[0] != num_frames:\n",
    "                        print(f\"Skipping chunk with {chunk.shape[0]} frames\")\n",
    "                        continue\n",
    "                    np.savez(video_path + \"_chunk_\" + str(counter), video=chunk, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset(32, \"video_dataset_CL_112_32frames\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SITUATION AWARENESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../label_generation/situation_awareness_labels.csv\")\n",
    "# template = np.zeros((2, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_SA(num_frames, folder, pad):\n",
    "    for user in os.listdir(\"../../user_data/\"):\n",
    "        for task_name in os.listdir(\"../../user_data/\" + user + \"/Video/Task 1/Facial Features/\"):\n",
    "            if task_name == \".DS_Store\":\n",
    "                continue\n",
    "            to_save = task_name if task_name[-1] != \"y\" else task_name[:-10]\n",
    "            file = f\"./{user}/{task_name}.json\"\n",
    "            c = df[\"name\"] == file\n",
    "            filtered_df = df[c]\n",
    "            if len(filtered_df) == 0:\n",
    "                print(f\"User {user} on task {task_name} is not available in the csv file\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Creating data file for user {user}, task {task_name}\")\n",
    "                label = filtered_df['labels'].iloc[0]\n",
    "                task_data = []\n",
    "                video_path = \"../../simple_datasets/Task 1/\" + folder + \"/\" + user + \"_\" + to_save\n",
    "                for frame in sorted(os.listdir(\"../../user_data/\" + user + \"/Video/Task 1/Facial Features/\" + task_name + \"/\" + task_name + \"_aligned/\")):\n",
    "                    image_path = \"../../user_data/\" + user + \"/Video/Task 1/Facial Features/\" + task_name + \"/\" + task_name + \"_aligned/\" + frame\n",
    "                    image = cv2.imread(image_path)\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    print(image_path)\n",
    "                    if pad:\n",
    "                        image = custom_pad_image(image, target_size=(224, 224))\n",
    "                    numpy_data = np.asarray(image).astype(np.float32)\n",
    "                    numpy_data = numpy_data.transpose(2, 1, 0)\n",
    "                    numpy_data = numpy_data / 255\n",
    "                    task_data.append(numpy_data)\n",
    "                task_data = np.array(task_data)\n",
    "                print(task_data.shape)\n",
    "                chunks = split_given_size(a=task_data, size=32, axis=0)\n",
    "                for counter, chunk in enumerate(chunks):\n",
    "                    # chunk = np.concatenate((chunk, template), axis=0)\n",
    "                    if chunk.shape[0] != num_frames:\n",
    "                        print(f\"Skipping chunk with {chunk.shape[0]} frames\")\n",
    "                        continue\n",
    "                    np.savez(video_path + \"_chunk_\" + str(counter), video=chunk, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset_SA(32, \"video_dataset_SA_112_32frames\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE TO CREATE SEPARATE FOLDS FOR TRAINING, TESTING, AND STORE PATHS IN TXT FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob(\"../../../video_dataset_CL_112_32frames/*.npz\")            # path to the newly created simple dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/cyan/AIDA3/cogmd/video_dataset_224_32frames\n",
      "mv: cannot move 'training' to a subdirectory of itself, 'training/training'\n"
     ]
    }
   ],
   "source": [
    "%cd ../../../video_dataset_224_32frames/                                              # cd to that folder\n",
    "%mkdir training\n",
    "%mv * training\n",
    "%mkdir testing\n",
    "%mkdir paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/cyan/AIDA3/cogmd/video_dataset_224_32frames/training\n"
     ]
    }
   ],
   "source": [
    "%cd ./training\n",
    "%mkdir fold_0\n",
    "%mkdir fold_1\n",
    "%mkdir fold_2\n",
    "%mkdir fold_3\n",
    "%mkdir fold_4\n",
    "%mkdir fold_5\n",
    "%mkdir fold_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv *8708506757* ./fold_0 \n",
    "%mv *3485568572* ./fold_0\n",
    "%mv *4795940856* ./fold_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv *2058939492* ./fold_1\n",
    "%mv *4217429651* ./fold_1\n",
    "%mv *2999828357* ./fold_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv *9793764153* ./fold_2\n",
    "%mv *2651031016* ./fold_2\n",
    "%mv *1008719828* ./fold_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv *5843924292* ./fold_3\n",
    "%mv *2325724317* ./fold_3\n",
    "%mv *3955372865* ./fold_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv *4741106167* ./fold_4\n",
    "%mv *1566954358* ./fold_4\n",
    "%mv *8346835623* ./fold_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv *7786511601* ./fold_5\n",
    "%mv *9115601756* ./fold_5\n",
    "%mv *7538467423* ./fold_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv *5012461204* ./fold_6\n",
    "%mv *3437429070* ./fold_6\n",
    "%mv *7799738638* ./fold_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv *4830336371* ../testing\n",
    "%mv *1691200944* ../testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(7):\n",
    "    fold_paths = glob.glob(f\"../../../video_dataset_SA_224_32frames/training/fold_{fold}/*.npz\")     # path to the dataset files\n",
    "    with open(f\"./fold_{fold}_paths.txt\", \"w\") as f:\n",
    "        for train_path in fold_paths:\n",
    "            f.write(train_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = glob.glob(f\"../../../video_dataset_SA_224_32frames/testing/*.npz\")                      # path to the dataset files\n",
    "with open(\"./test_paths.txt\", \"w\") as f:\n",
    "    for test_path in test_paths:\n",
    "        f.write(test_path + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
